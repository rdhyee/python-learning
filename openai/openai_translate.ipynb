{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdhyee_utils.clipboard.macos import GeneralPasteboard, ptypes\n",
    "pb = GeneralPasteboard()\n",
    "data = pb.get_string()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sh\n",
    "\n",
    "input_text = sh.pbpaste()\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sh\n",
    "import shlex\n",
    "import json\n",
    "\n",
    "from diff_match_patch import diff_match_patch\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from diff_match_patch import diff_match_patch\n",
    "\n",
    "input_text = sh.pbpaste()\n",
    "\n",
    "# r = json.loads(sh.llm(shlex.split('''-t copyedit ''')  + [input_text]  ))\n",
    "r = sh.llm([\"-t\", \"copyedit\", input_text ] )\n",
    "try:\n",
    "    r = json.loads(r)\n",
    "except json.JSONDecodeError:\n",
    "    print (r)\n",
    "    raise\n",
    "\n",
    "output_text = r.get('edited_text')\n",
    "comments = r.get('comments_and_questions')\n",
    "\n",
    "print (output_text)\n",
    "sh.pbcopy(_in=output_text)\n",
    "\n",
    "for line in comments:\n",
    "    print (line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dmp = diff_match_patch()\n",
    "dmp.Diff_Timeout = 0 # unlimited\n",
    "\n",
    "patches = dmp.patch_make(input_text, output_text)\n",
    "diff_from_patches = dmp.patch_toText(patches)\n",
    "\n",
    "diffs = dmp.diff_main(input_text, output_text)\n",
    "diff_html = dmp.diff_prettyHtml(diffs)\n",
    "\n",
    "display(HTML(diff_html))\n",
    "\n",
    "# r = sh.llm(\"number of perfect numbers between 1 and 1000\")\n",
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff_from_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://llm.datasette.io/en/stable/python-api.html\n",
    "\n",
    "import llm\n",
    "\n",
    "model = llm.get_model(\"gpt-4o-mini\")\n",
    "\n",
    "# use template copyedit\n",
    "# llm -t copyedit \"Life is it's own reward.\"\n",
    "response = model.prompt(prompt=\"Life is it's own reward.\") #  template=\"copyedit\")\n",
    "# response = model.prompt(\"Five surprising names for a pet pelican\")\n",
    "# print(response.text())\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llm\n",
    "\n",
    "model = llm.get_model(\"gpt-4o-mini\")\n",
    "\n",
    "# Load the template\n",
    "template = llm.cli.load_template(\"copyedit\")\n",
    "\n",
    "# Use the template with your prompt\n",
    "response = model.prompt(template.format(text=\"Life is it's own reward.\"))\n",
    "\n",
    "# Print the response\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using OpenAI to translate Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path as P\n",
    "from lxml import etree\n",
    "from itertools import islice\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the XML in .bike and parse using lxml \n",
    "# get all the p text\n",
    "# https://lxml.de/parsing.html\n",
    "\n",
    "\n",
    "def extract_p_text(file_path):\n",
    "    # Ensure the file path is a Path object\n",
    "    if not isinstance(file_path, P):\n",
    "        file_path = P(file_path)\n",
    "\n",
    "    # Read the xml file\n",
    "    xml_data = file_path.read_bytes()\n",
    "\n",
    "    # Parse the XML data\n",
    "    root = etree.fromstring(xml_data)\n",
    "\n",
    "    # Find all 'p' elements\n",
    "    p_elements = root.findall('.//p')\n",
    "\n",
    "    # Extract and return the text from the 'p' elements\n",
    "\n",
    "    for p in p_elements:\n",
    "        if p.text is not None:\n",
    "            yield (p.text)\n",
    "\n",
    "# Usage\n",
    "file_path = P.home() / \"Downloads\" / \"moby_dick.bike\" \n",
    "p_text_list = extract_p_text(file_path)\n",
    "\n",
    "for i, text in islice(enumerate(p_text_list), 10):\n",
    "    print(f\"Paragraph {i+1}: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = P.home() / \"Downloads\" / \"moby_dick.bike\" \n",
    "\n",
    "paragraphs = list(extract_p_text(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Series(paragraphs)\n",
    "max(s.apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "openai_api_ref = \"op://Private/g2mohpraf2d67jktlsoljc43si/Section_caj3qfdvfnkqfxn63jhjpydb7e/api key\"\n",
    "claude_api_ref = \"op://Private/Claude key-20240304/credential\"\n",
    "\n",
    "\n",
    "def run_command(cmd):\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, shell=True)\n",
    "    return result.stdout + result.stderr\n",
    "\n",
    "def op_read(api_ref):\n",
    "    cmd = f'op read \"{api_ref}\"'\n",
    "    api_key = run_command(cmd).strip()\n",
    "    return api_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Assuming the OpenAI API key is set as an environment variable:\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Ensure the API key is available\n",
    "if api_key is None:\n",
    "    raise ValueError(\"API key for OpenAI is not set\")\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a sentence in English, and your task is to translate it into French.\\n\\n\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hello world\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Bonjour le monde\"\n",
    "    },\n",
    "       {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Je speak French fairly well.\"\n",
    "    },\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming 'response' is the variable holding the API response.\n",
    "# You might need to use response.json() if you're using requests library to fetch the data.\n",
    "\n",
    "# Convert the response to a JSON object if not already done\n",
    "response_json = json.loads(response.json())\n",
    "\n",
    "\n",
    "# Accessing the list of messages in the response\n",
    "message = response_json['choices'][0]['message']\n",
    "\n",
    "    \n",
    "role = message['role']\n",
    "content = message['content']\n",
    "print(f\"Role: {role}, Content: {content}\")\n",
    "\n",
    "# To extract specific translations or interactions, you could filter by role\n",
    "# For example, to print only the assistant's translations:\n",
    "print(\"\\nTranslations by the assistant:\")\n",
    "if message['role'] == 'assistant':\n",
    "    print(message['content'])\n",
    "\n",
    "# In case you want to handle more complex structures or search for specific dialog turns\n",
    "# You might implement additional parsing logic here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the response text\n",
    "print(response.choices[0].text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"\\r{i}\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 1001\n",
    "STOP = 3000\n",
    "\n",
    "responses = []\n",
    "for (i,p) in enumerate(paragraphs[START:STOP]):\n",
    "    \n",
    "    print(f\"\\r{i}\", end=\"\")\n",
    "    messages = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a sentence in English, and your task is to translate it into French.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": p \n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\" \n",
    "    }\n",
    "  ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages= messages,\n",
    "        temperature=0,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in responses:\n",
    "    print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use openai to return the list of models, and their descriptions and costs\n",
    "# https://beta.openai.com/docs/api-reference/list-engines\n",
    "\n",
    "\n",
    "models = openai.Model.list()\n",
    "\n",
    "for model in models['data']:\n",
    "    print(f\"Model ID: {model['id']}, Model Name: {model['object']}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "# URL of the page you want to scrape\n",
    "url = 'https://openai.com/pricing'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using lxml\n",
    "tree = html.fromstring(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the XPath query to find the elements you're interested in\n",
    "# This is a generic XPath and should be customized for your specific needs\n",
    "# For example, to extract titles: '//h1/text()' or to extract prices: '//span[@class=\"price\"]/text()'\n",
    "xpath_query = '//*[@id=\"gpt-4-turbo\"]/div/div/div[1]/div/div[1]/h3'\n",
    "\n",
    "# Use the XPath query to extract the desired information\n",
    "extracted_data = tree.xpath(xpath_query)\n",
    "\n",
    "# Print the extracted data\n",
    "for data in extracted_data:\n",
    "    print(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chat.openai.com/share/d06bc114-e94d-48be-bf96-b9f73a2e9ea6\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define your local data to compare against\n",
    "local_data = {\n",
    "    \"text_models\": {\n",
    "        \"gpt-4\": {\n",
    "            \"prompt_tokens\": {\n",
    "                \"8k_context\": \"$0.03 / 1K tokens\",\n",
    "                \"32k_context\": \"$0.06 / 1K tokens\"\n",
    "            },\n",
    "            \"sampled_tokens\": {\n",
    "                \"8k_context\": \"$0.06 / 1K tokens\",\n",
    "                \"32k_context\": \"$0.12 / 1K tokens\"\n",
    "            }\n",
    "        },\n",
    "        # Add other local data similarly\n",
    "    },\n",
    "    # Define other model types similarly\n",
    "}\n",
    "\n",
    "def fetch_pricing():\n",
    "    url = \"https://openai.com/pricing\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Assuming data is stored in a table or a specific div - adjust as necessary\n",
    "    data_div = soup.find_all(\"div\", class_=\"pricing-table\")\n",
    "    fetched_data = {}\n",
    "\n",
    "    for div in data_div:\n",
    "        model_name = div.find(\"h3\").text\n",
    "        price_info = div.find_all(\"p\")  # Assuming price is in <p> tags\n",
    "        prices = {p.text.split(':')[0].strip(): p.text.split(':')[1].strip() for p in price_info}\n",
    "        fetched_data[model_name] = prices\n",
    "\n",
    "    return fetched_data\n",
    "\n",
    "def compare_data(fetched_data):\n",
    "    differences = {}\n",
    "    for category in local_data:\n",
    "        if category in fetched_data:\n",
    "            for model, details in local_data[category].items():\n",
    "                if model in fetched_data[category]:\n",
    "                    for detail, value in details.items():\n",
    "                        if detail in fetched_data[category][model]:\n",
    "                            fetched_value = fetched_data[category][model][detail]\n",
    "                            if fetched_value != value:\n",
    "                                differences[model + ' ' + detail] = (value, fetched_value)\n",
    "    return differences\n",
    "\n",
    "# Fetch the latest pricing data from OpenAI's website\n",
    "fetched_pricing_data = fetch_pricing()\n",
    "\n",
    "# Compare the fetched data with local data\n",
    "differences = compare_data(fetched_pricing_data)\n",
    "\n",
    "# Output the differences\n",
    "if differences:\n",
    "    print(\"There are differences in the pricing data:\")\n",
    "    for diff in differences:\n",
    "        print(f\"{diff}: Local = {differences[diff][0]}, Fetched = {differences[diff][1]}\")\n",
    "else:\n",
    "    print(\"The local data matches the fetched data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_with_whitespace(s):\n",
    "    return re.split(r'(\\s+)', s)\n",
    "\n",
    "# Example usage:\n",
    "s = 'Hello   World \\n This is a test'\n",
    "print(split_with_whitespace(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hello world code for using difflib to compare two text blobs and show the diff in HTML format\n",
    "# https://stackoverflow.com/questions/47694421/difflib-html-diff-output\n",
    "\n",
    "import re\n",
    "import difflib\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "def tokenize(s):\n",
    "    \"\"\"Tokenize a string into words, punctuation, and whitespace.\n",
    "    \"\"\"\n",
    "    return re.findall(r'\\w+|\\s+|\\W', s)\n",
    "    # return re.split(r'(\\s+|\\W+)', s)\n",
    "\n",
    "\n",
    "def compare_by_chars(text1, text2):\n",
    "    words1 = text1\n",
    "    words2 = text2\n",
    "    diff = difflib.ndiff(words1, words2)\n",
    "    return diff\n",
    "\n",
    "def compare_by_words(text1, text2):\n",
    "    lines1 = tokenize(text1)\n",
    "    lines2 = tokenize(text2)\n",
    "    diff = difflib.ndiff(lines1, lines2, linejunk=lambda s: False)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def ndiff_as_html(diff):\n",
    "    html = []\n",
    "    for line in diff:\n",
    "        if line.startswith('- '):\n",
    "            html.append(f'<span style=\"background-color: #ffcccc;\">{line[2:]}</span>')\n",
    "        elif line.startswith('+ '):\n",
    "            html.append(f'<span style=\"background-color: #ccffcc;\">{line[2:]}</span>')\n",
    "        elif line.startswith('? '):\n",
    "            html.append(f'<span style=\"background-color: #ffff99;\">{line[2:]}</span>')\n",
    "        elif line.startswith('  '):\n",
    "            html.append(f'<span>{line[2:]}</span>')\n",
    "    return ''.join(html)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text1 = \"\"\"\n",
    "I'm going to work from the bottom up and top down and from sideways too. So one idea for a specific project that I want to build very soon is to hook up a writing environment like Microsoft Word which has track changes and allow it to let me query something like chat gpt API to have it lightly copy at it my text and instead of just replacing all my text wholesale with the new revision to rather insert it and display the suggested changes as granular changes I can accept or reject. That is, I want to use the track changes to let me have much more fine grain control over my interactions with a large language model.\n",
    "\"\"\".strip()\n",
    "\n",
    "text2 = \"\"\"\n",
    "I'm going to work from the bottom up and top down, and from sideways too. So one idea for a specific project that I want to build very soon is to hook up a writing environment like Microsoft Word, which has track changes, and allow it to let me query something like the ChatGPT API to have it lightly copy-edit my text. Instead of just replacing all my text wholesale with a new revision, I want it to insert the suggested changes and display them as granular changes I can accept or reject. That is, I want to use the track changes feature to give me much more fine-grained control over my interactions with a large language model.\n",
    "\"\"\".strip()\n",
    "\n",
    "# diff = compare_by_chars(text1, text2)\n",
    "diff = compare_by_words(text1, text2)\n",
    "\n",
    "HTML(ndiff_as_html(diff))\n",
    "\n",
    "# HTML(difflib.HtmlDiff().make_table(tokenize(text1), tokenize(text2), context=True, numlines=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmp = diff_match_patch()\n",
    "dmp.Diff_Timeout = 0 # unlimited\n",
    "\n",
    "diffs = dmp.diff_main(text1, text2)\n",
    "diff_html = dmp.diff_prettyHtml(diffs)\n",
    "\n",
    "display(HTML(diff_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_match_patch import diff_match_patch\n",
    "\n",
    "dmp = diff_match_patch()\n",
    "dmp.Diff_Timeout = 0 # unlimited\n",
    "\n",
    "patches = dmp.patch_make(text1, text2)\n",
    "diff = dmp.patch_toText(patches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from diff_match_patch import diff_match_patch\n",
    "\n",
    "text1=\"\"\"\n",
    "1.2.1 \n",
    "en raison des dommages corporels, matériels et immatériels consécutifs ou \n",
    "non consécutifs subis par des tiers résultant d’une pollution imputable aux \n",
    "activités garanties de l’assuré que ce soient celles réalisées sur les sites \n",
    "couverts ou au titre des opérations couvertes. \n",
    " \n",
    "\n",
    " \n",
    " \n",
    "201811 \n",
    "cg_chubb protection environnementale_2017 \n",
    "4 \n",
    " \n",
    "sont également inclus dans cette garantie, en tant qu’ils sont causés par une pollution imputable aux activités \n",
    "garanties de l’assuré que ce soient celles réalisées sur les sites couverts ou au titre des opérations couvertes: \n",
    " \n",
    "les frais de dépollution et de remise en etat dès lors que ces frais sont engagés pour réparer des \n",
    "dommages matériels subis par des tiers ; \n",
    " \n",
    "les conséquences pécuniaires des dommages subis par des biens confiés à l’assuré ou par des biens \n",
    "appartenant aux préposés de l’assuré dans la limite fixée aux conditions particulières. \n",
    "1.2.2 en raison des frais de réparation du préjudice ecologique, des dépenses de prévention du préjudice ecologique \n",
    "et du coût des mesures raisonnables relatifs à un préjudice écologique résultant d’une pollution imputable aux \n",
    "activités garanties de l’assuré que ce soit celles réalisées sur les sites couverts ou au titre des opérations \n",
    "couvertes. pour les seules atteintes à la biodiversité, la présente garantie 1.2.2. couvre également les frais de \n",
    "réparation du préjudice ecologique, les dépenses de prévention du préjudice ecologique et le coût des mesures \n",
    "raisonnables relatifs à un préjudice écologique afférents à ces atteintes à la biodiversité même lorsqu’elles n’ont \n",
    "pas pour origine une pollution dès lors qu’elles résultent d’un fait fortuit, imprévu et involontaire et sont \n",
    "imputables aux activités garanties de l’assuré que ce soit celles réalisées sur les sites couverts ou au titre des \n",
    "opérations couvertes . \n",
    "sont également inclus dans la garantie 1.2 les frais de défense et recours tels que définis à l’article 2.20. \n",
    "1.3 \n",
    "garantie responsabilité environnementale  \n",
    "les frais de réparation du dommage environnemental incombant à l’assuré au titre de sa responsabilité \n",
    "environnementale lorsque, conformément à l’article l. 162-11 du code de l’environnement ou aux textes équivalents \n",
    "adoptés par chacun des etats membres de l’union européenne pour transposer la directive européenne ce 2004/35, \n",
    "l’assuré se voit prescrire par une autorité publique compétente de mettre en œuvre des mesures destinées à réparer un \n",
    "dommage environnemental imputable aux activités garanties de l’assuré réalisées sur les sites couverts. \n",
    "les frais de réparation du dommage environnemental incombant à l’assuré au titre de sa responsabilité \n",
    "environnementale lorsque, conformément à l’article l. 162-11 du code de l’environnement ou aux textes équivalents \n",
    "adoptés par chacun des etats membres de l’union européenne pour transposer la directive européenne ce 2004/35, \n",
    "l’assuré se voit prescrire par une autorité publique compétente de mettre en œuvre des mesures destinées à réparer un \n",
    "dommage environnemental imputable aux activités garanties de l’assuré réalisées au titre des opérations couvertes. \n",
    "les frais de réparation du dommage environnemental incombant à l’assuré au titre de sa responsabilité \n",
    "environnementale lorsque, conformément à l’article l. 162-11 du code de l’environnement ou aux textes équivalents \n",
    "adoptés par les etats membres de l’union européenne pour transposer la directive européenne ce 2004/35, l’assuré se \n",
    "voit prescrire par l’autorité publique compétente de mettre en œuvre des mesures destinées à réparer un dommage \n",
    "environnemental imputable aux activités garanties de l’assuré provenant des produits couverts. \n",
    "les sommes exposées par l'etat au titre des frais de réparation du dommage environnemental conformément aux \n",
    "articles l. 162-14 et suivants du code de l’environnement ou aux textes équivalents adoptés par les etats membres de \n",
    "l’union européenne pour transposer la directive européenne ce 2004/35 et dont le remboursement est réclamé à \n",
    "l'assuré au titre de sa responsabilité environnementale dès lors que le dommage environnemental résulte des activités \n",
    "garanties de l’assuré quelles soient réalisées sur les sites couverts, au titre des opérations couvertes ou provenant des \n",
    "produits couverts. \n",
    "la présente garantie couvre également les frais de réparation du dommage environnemental relevant de la \n",
    "responsabilité environnementale de l’assuré même lorsqu’ils n’ont pas pour origine une pollution. dès lors qu’elles sont \n",
    "imputables aux activités garanties de l’assuré que ce soit celles réalisées sur les sites couverts ou au titre des opérations \n",
    "couvertes . \n",
    "sont également inclus dans la garantie 1.3 les frais de défense et recours tels que définis à l’article 2.20. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "text2=\"\"\"\n",
    "1.2.1 \n",
    "en raison des dommages corporels, matériels et immatériels consécutifs ou \n",
    "non consécutifs subis par des tiers résultant d’une pollution imputable aux \n",
    "activités garanties de l’assuré. sont également inclus dans cette garantie : \n",
    "• \n",
    "les frais de dépollution et de remise en état engagés pour réparer des \n",
    "dommages matériels subis par les tiers ; \n",
    "• \n",
    "les conséquences pécuniaires des dommages subis par des biens confiés à \n",
    "l’assuré ou par des biens appartenant aux préposés de l’assuré dans la \n",
    "limite fixée aux conditions particulières, \n",
    "dès lors qu’ils sont causés par une pollution imputable aux activités garanties \n",
    "de l’assuré et font l’objet d’une réclamation du tiers.  \n",
    "1.2.2 en raison des préjudices écologiques résultant d’une pollution imputable aux \n",
    "activités garanties de l’assuré. pour les seules atteintes à la biodiversité, la \n",
    "présente garantie 1.2.2. couvre également les préjudices écologiques même \n",
    "lorsqu’elles n’ont pas pour origine une pollution dès lors qu’elles résultent d’un \n",
    "fait fortuit, imprévu et involontaire et sont imputables aux activités garanties \n",
    "de l’assuré. \n",
    "sont inclus dans la garantie 1.2 les frais de défense et recours tels que définis à \n",
    "l’article 2.20. \n",
    "conditions générales \n",
    "\n",
    " \n",
    "202306 \n",
    "cg_chubb protection environnementale_2023 \n",
    "4 \n",
    " \n",
    "1.3 \n",
    "garantie responsabilité environnementale  \n",
    "les frais de réparation du dommage environnemental incombant à l’assuré au titre de sa responsabilité \n",
    "environnementale lorsque, conformément à l’article l. 162-11 du code de l’environnement ou aux textes équivalents \n",
    "adoptés par chacun des etats membres de l’union européenne pour transposer la directive européenne ce 2004/35, \n",
    "l’assuré se voit prescrire par une autorité publique compétente de mettre en œuvre des mesures destinées à réparer un \n",
    "dommage environnemental imputable aux activités garanties de l’assuré. \n",
    "les sommes exposées par l'etat au titre des frais de réparation du dommage environnemental conformément aux \n",
    "articles l. 162-14 et suivants du code de l’environnement ou aux textes équivalents adoptés par les etats membres de \n",
    "l’union européenne pour transposer la directive européenne ce 2004/35 et dont le remboursement est réclamé à \n",
    "l'assuré au titre de sa responsabilité environnementale dès lors que le dommage environnemental résulte des activités \n",
    "garanties de l’assuré. \n",
    "la présente garantie couvre également les frais de réparation du dommage environnemental relevant de la \n",
    "responsabilité environnementale de l’assuré même lorsqu’ils n’ont pas pour origine une pollution dès lors qu’ils sont \n",
    "imputables aux activités garanties de l’assuré. \n",
    "sont également inclus dans la garantie 1.3 les frais de défense et recours tels que définis à l’article 2.20. \n",
    "\"\"\"\n",
    "\n",
    "dmp = diff_match_patch()\n",
    "dmp.Diff_Timeout = 0 # unlimited\n",
    "\n",
    "diffs = dmp.diff_main(text1, text2)\n",
    "diff_html = dmp.diff_prettyHtml(diffs)\n",
    "\n",
    "display(HTML(diff_html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "source_code = inspect.getsource(difflib.IS_LINE_JUNK)\n",
    "print(source_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "original = \"The quick brown fox.\"\n",
    "edited = \"The quick brown foxx.\"\n",
    "\n",
    "diff = difflib.ndiff(original, edited)\n",
    "print('\\n'.join(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
